{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Basic Usage of SiML\n\nSiML facilitates machine learning processes, including preprocessing, learning,\nand prediction.\nWe will cover the entire pipeline of a machine learning process using the\ngradient dataset example.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary modules including :mod:`siml`.\n`FEMIO <https://ricosjp.github.io/femio/>`_ is used to generate data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pathlib\nimport shutil\n\nimport femio\nimport numpy as np\nimport siml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clean up old data if exists.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shutil.rmtree('00_basic_data/raw', ignore_errors=True)\nshutil.rmtree('00_basic_data/interim', ignore_errors=True)\nshutil.rmtree('00_basic_data/preprocessed', ignore_errors=True)\nshutil.rmtree('00_basic_data/model', ignore_errors=True)\nshutil.rmtree('00_basic_data/inferred', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data generation\nFirst, we define a function to generate data and call it\nto create the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_data(output_directory):\n    # Generate a simple mesh\n    n_x_element = np.random.randint(5, 10)\n    n_y_element = np.random.randint(5, 10)\n    n_z_element = 1\n    fem_data = femio.generate_brick(\n        'hex',\n        n_x_element=n_x_element,\n        n_y_element=n_y_element,\n        n_z_element=n_z_element,\n        x_length=n_x_element,\n        y_length=n_y_element,\n        z_length=n_z_element)\n\n    # Generate scalar field phi and the gradient field associated to it\n    scale = 1 / 5\n    nodes = np.copy(fem_data.nodes.data)\n    nodes[:, -1] = 0.  # Make pseudo 2D\n    shift = np.random.rand(1, 3) / scale\n    shift[:, -1] = 0\n    square_norm = .5 * np.linalg.norm(nodes - shift, axis=1)**2\n    phi = np.cos(square_norm * scale)[:, None]\n    grad = - np.sin(square_norm * scale)[:, None] * scale * (nodes - shift)\n\n    # Write data\n    fem_data.nodal_data.update_data(\n        fem_data.nodes.ids, {'phi': phi, 'grad': grad},\n        allow_overwrite=False)\n    fem_data.write(\n        'ucd', output_directory / 'mesh.inp')\n    return\n\n\nn_train_sample = 20\nfor i in range(n_train_sample):\n    generate_data(pathlib.Path(f\"00_basic_data/raw/train/{i}\"))\n\nn_validation_sample = 5\nfor i in range(n_validation_sample):\n    generate_data(pathlib.Path(f\"00_basic_data/raw/validation/{i}\"))\n\nn_test_data = 5\nfor i in range(n_validation_sample):\n    generate_data(pathlib.Path(f\"00_basic_data/raw/test/{i}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the process finished successfully, the data should look as follows\n(visualization using `ParaView <https://www.paraview.org/>`_).\n\n<img src=\"file://../../examples/00_basic_fig/grad_train.png\" width=\"400\">\n\nHere, we consider the task to predict the gradient field\n(arrows in the figure above) from the input of the scalar field\n(color map in the figure above).\n\n## Data preprocessing\nHere, we extract features from the generated dataset.\nData generation and feature extraction is something SiML does not manage\nbecause the library does not know what simulation to run and what features to\nextract.\nTherefore, users should write some code for these two parts,\nalthough SiML (and FEMIO) can support it.\n\nNow, define a call-back function to extract features from the dataset.\nThe function takes two arguments,\n:code:`femio.FEMData` object representing a sample in the dataset and\n:code:`pathlib.Path` object representing an output directory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def conversion_function(fem_data, raw_directory):\n\n    node = fem_data.nodes.data\n\n    phi = fem_data.nodal_data.get_attribute_data('phi')\n    grad = fem_data.nodal_data.get_attribute_data('grad')[..., None]\n\n    # Generate renormalized adjacency matrix based on Kipf and Welling 2016\n    nodal_adj = fem_data.calculate_adjacency_matrix_node()\n    nodal_nadj = siml.prepost.normalize_adjacency_matrix(nodal_adj)\n\n    # Generate IsoAM based on Horie et al. 2020\n    nodal_isoam_x, nodal_isoam_y, nodal_isoam_z = \\\n        fem_data.calculate_spatial_gradient_adjacency_matrices(\n            'nodal', n_hop=1, moment_matrix=True)\n\n    dict_data = {\n        'node': node,\n        'phi': phi,\n        'grad': grad,\n        'nodal_nadj': nodal_nadj,\n        'nodal_isoam_x': nodal_isoam_x,\n        'nodal_isoam_y': nodal_isoam_y,\n        'nodal_isoam_z': nodal_isoam_z,\n    }\n    return dict_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From here, SiML can manage most of the process.\nPlease download\n`data.yml\n<https://github.com/ricosjp/siml/examples/00_basic_data/data.yml>`_\nfile and place it in the :code:`00_basic_data` directory.\nSiML uses YAML files as setting files to control its behavior.\nBasically, each setting component can be omitted, and if so,\nthe default setting will be adopted.\nThe relevant contents of the YAML file are as follows.\n\n.. code-block:: yaml\n\n  data:  # Data directory setting\n    raw: 00_basic_data/raw   # Row data\n    interim: 00_basic_data/interim  # Extracted features\n    preprocessed: 00_basic_data/preprocessed  # Preprocessed data\n    inferred: 00_basic_data/inferred  # Predicted data\n  conversion:  # Feature extraction setting\n    file_type: 'ucd'  # File type to be read\n    required_file_names:  # Files to be regarded as data\n      - '*.inp'\n\nAs can be seen, the structure of the directory follows that of the\n`Cookiecutter Data Science\n<https://drivendata.github.io/cookiecutter-data-science/>`_.\n\nNow, generate a :class:`~siml.prepost.RawConverter` object by feeding the\nYAML file and perform feature extraction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "settings_yaml = pathlib.Path('00_basic_data/data.yml')\nraw_converter = siml.preprocessing.converter.RawConverter.read_settings(\n    settings_yaml, conversion_function=conversion_function)\nraw_converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, perform preprocessing, e.g., scaling of the data.\nThe relevant part of the YAML file is as follows.\n\n.. code-block:: yaml\n\n  preprocess:  # Data scaling setting\n    node: std_scale  # Standardization without subtraction of the mean\n    phi: standardize   # Standardization\n    grad: std_scale\n    nodal_nadj: identity  # No scaling\n    nodal_isoam_x: identity\n    nodal_isoam_y: identity\n    nodal_isoam_z: identity\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "preprocessor = siml.preprocessing.ScalingConverter.read_settings(settings_yaml)\npreprocessor.fit_transform()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\nThen, we move on to the training.\nPlease download\n`isogcn.yml\n<https://github.com/ricosjp/siml/examples/00_basic_data/isogcn.yml>`_\nfile and place it in the :code:`00_basic_data` directory.\nIn the YAML file, the setting for the trainer is written as follows.\n\n.. code-block:: yaml\n\n  trainer:\n    output_directory: 00_basic_data/model  # Output directory\n    inputs:  # Input data specification\n      - name: phi  # Input data name\n        dim: 1  # phi's dimention\n    support_input:  # Support inputs e.g. adjacency matrix\n      - nodal_isoam_x\n      - nodal_isoam_y\n      - nodal_isoam_z\n    outputs:\n      - name: grad  # Output data name\n        dim: 1  # gradient's dimention (the shape is in [n, 3, 1], so 1)\n    prune: false\n    n_epoch: 100  # The nmber of epochs\n    log_trigger_epoch: 1  # The period to log the training\n    stop_trigger_epoch: 5  # The period to condider early stopping\n    seed: 0  # The rondom seed\n    lazy: false  # If true, data is read lazily rather than on-memory\n    batch_size: 4  # The size of the batch\n    num_workers: 0  # The number of processes to load data (0 means serial)\n    figure_format: png  # Format of the output figures (the default is pdf)\n\nIn the same file, the setting for the machine learning model is also written.\nIn this example, we use `IsoGCN <https://arxiv.org/abs/2005.06316>`_\n(Horie et al. ICLR 2021).\nWe can try many machine learning trials with various training and model\nsettings by editing the YAML file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "isogcn_yaml = pathlib.Path('00_basic_data/isogcn.yml')\ntrain_main_setting = siml.setting.MainSetting.read_settings_yaml(\n    isogcn_yaml\n)\ntrainer = siml.trainer.Trainer(train_main_setting)\ntrainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results of the training is stored in\n:code:`00_basic_data/model`. If you remove :code:`output_directory` line\nin the YAML file, the output directory will be determined automatically.\n\n::\n\n  00_basic_data/model\n  \u251c\u2500\u2500 log.csv               # Logfile of the training\n  \u251c\u2500\u2500 network.png           # Network structure figure\n  \u251c\u2500\u2500 plot.png              # Loss-epoch plot\n  \u251c\u2500\u2500 settings.yml          # Trainin setting file for reproducibility\n  \u251c\u2500\u2500 snapshot_epoch_1.pth  # Model parameter at the epoch 1\n  \u251c\u2500\u2500 snapshot_epoch_2.pth\n  \u251c\u2500\u2500 snapshot_epoch_3.pth\n  .\n  .\n  .\n\nThe network structure used in the training is shown below.\n\n<img src=\"file://../../examples/00_basic_data/model/network.png\" width=\"200\">\n\nThe loss vs. epoch curve is shown below.\n\n<img src=\"file://../../examples/00_basic_data/model/plot.png\" width=\"400\">\n\n## Prediction\nUsing the trained model, we can make a prediction.\nIn the isogcn YAML file, the setting for inference is also written.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inferer = siml.inferer.Inferer.read_settings_file(\n    isogcn_yaml, model_path=trainer.setting.trainer.output_directory)\ninferer.infer(\n    data_directories=[pathlib.Path('00_basic_data/preprocessed/test')],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The predicted data is stored in\n:code:`00_basic_data/inferred/model_[date]/test`\n(:code:`[date]` depends on the date when you run this script.)\n\nThe structure of the directory is as follows.\n\n::\n\n  00_basic_data/inferred/model_[date]\n   \u251c\u2500\u2500 log.csv           # Summary file\n   \u251c\u2500\u2500 settings.yml      # Setting used to prediction (for reproducibility)\n   \u2514\u2500\u2500 test\n       \u251c\u2500\u2500 0\n       \u2502\u00a0\u00a0 \u251c\u2500\u2500 grad.npy  # Predicted gradient\n       \u2502\u00a0\u00a0 \u251c\u2500\u2500 mesh.inp  # AVD UCD format file for visualization\n       \u2502\u00a0\u00a0 \u2514\u2500\u2500 phi.npy   # Input data\n       \u251c\u2500\u2500 1\n       \u2502\u00a0\u00a0 \u251c\u2500\u2500 grad.npy\n       \u2502\u00a0\u00a0 \u251c\u2500\u2500 mesh.inp\n       \u2502\u00a0\u00a0 \u2514\u2500\u2500 phi.npy\n       .\n       .\n       .\n\nThe predicted result will look as follows\n(left: ground truth, right: prediction). Looks good!\n\n<img src=\"file://../../examples/00_basic_fig/res.png\" width=\"400\">\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}